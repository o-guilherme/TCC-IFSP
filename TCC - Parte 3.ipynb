{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04636678-64b6-4983-bfb1-e348fdf8f183",
   "metadata": {},
   "source": [
    "# IFSP - Câmpus Campinas\n",
    "\n",
    "## Análise sobre a previsibilidade das decisões de admissibilidade no Superior Tribunal de Justiça usando inteligência artificial\n",
    "\n",
    "#### Aluno: Guilherme Cioldin Dainese\n",
    "\n",
    "### Parte 3 - Processamento dos textos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68d0ff0-cd0c-4982-a0d6-4cb16c0c006a",
   "metadata": {},
   "source": [
    "### 3.1 Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0efc8ed0-8726-4839-a78c-3c5db53d26ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import neattext.functions as ntx\n",
    "import spacy\n",
    "import neattext as nt\n",
    "import re\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "tqdm.pandas()  # Inicializa a integração do tqdm com pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "309d8994-172d-4490-a222-4c04ec2fa4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/guilherme/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8005b3f-40fd-4297-9c7c-1107973981c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqDocumento</th>\n",
       "      <th>numeroRegistro</th>\n",
       "      <th>ministro</th>\n",
       "      <th>teor</th>\n",
       "      <th>descricaoMonocratica</th>\n",
       "      <th>assuntos</th>\n",
       "      <th>y</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178153183</td>\n",
       "      <td>202300036881</td>\n",
       "      <td>JOÃO OTÁVIO DE NORONHA</td>\n",
       "      <td>Negando</td>\n",
       "      <td>Conhecido o recurso e não-provido</td>\n",
       "      <td>9607</td>\n",
       "      <td>0</td>\n",
       "      <td>[Rua Pedro Ferreira, nº 155 - 7º Andar - Sala ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181376805</td>\n",
       "      <td>202202985103</td>\n",
       "      <td>NANCY ANDRIGHI</td>\n",
       "      <td>Negando</td>\n",
       "      <td>Agravo conhecido para não conhecer do Recurso ...</td>\n",
       "      <td>9607</td>\n",
       "      <td>0</td>\n",
       "      <td>[ \\nPJ 571059\\nEXCELENTÍSSIMO SENHOR DOUTOR DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196160898</td>\n",
       "      <td>202301575526</td>\n",
       "      <td>MARIA THEREZA DE ASSIS MOURA</td>\n",
       "      <td>Não Conhecendo</td>\n",
       "      <td>Não conhecido o recurso</td>\n",
       "      <td>9607</td>\n",
       "      <td>0</td>\n",
       "      <td>[ \\nBANDEIRA &amp; BARROS\\nAdvocacia e Consultoria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220390496</td>\n",
       "      <td>202302743171</td>\n",
       "      <td>MARIA THEREZA DE ASSIS MOURA</td>\n",
       "      <td>Não Conhecendo</td>\n",
       "      <td>Não conhecido o recurso</td>\n",
       "      <td>9607</td>\n",
       "      <td>0</td>\n",
       "      <td>[Num. 161104655 - Pág. 1\\nAssinado eletronicam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>216103802</td>\n",
       "      <td>202302956038</td>\n",
       "      <td>MARIA THEREZA DE ASSIS MOURA</td>\n",
       "      <td>Não Conhecendo</td>\n",
       "      <td>Não conhecido o recurso</td>\n",
       "      <td>9607</td>\n",
       "      <td>0</td>\n",
       "      <td>[ \\n \\n \\nEXCELENTÍSSIMO SENHOR DESEMBARGADOR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>192080215</td>\n",
       "      <td>202300721459</td>\n",
       "      <td>JOÃO OTÁVIO DE NORONHA</td>\n",
       "      <td>Concedendo</td>\n",
       "      <td>Conhecido o recurso e provido</td>\n",
       "      <td>12401,7779,7780,9607</td>\n",
       "      <td>1</td>\n",
       "      <td>[ \\nPágina 1 de 17 \\n \\n \\n \\nEXMO. SR. DR. DE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>204842588</td>\n",
       "      <td>202203536482</td>\n",
       "      <td>JOÃO OTÁVIO DE NORONHA</td>\n",
       "      <td>Concedendo</td>\n",
       "      <td>Conhecido o recurso e provido em parte</td>\n",
       "      <td>9607</td>\n",
       "      <td>1</td>\n",
       "      <td>[ \\n \\nAv. T 05, Qd. 04, Lote 17, Sala Térrea,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>179332552</td>\n",
       "      <td>202203993058</td>\n",
       "      <td>MARCO BUZZI</td>\n",
       "      <td>Concedendo</td>\n",
       "      <td>Conhecido o recurso e provido</td>\n",
       "      <td>9607</td>\n",
       "      <td>1</td>\n",
       "      <td>[MARINGÁ/PR \\nEndereço: Rua João Paulino Vieir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>190594784</td>\n",
       "      <td>202301534845</td>\n",
       "      <td>NANCY ANDRIGHI</td>\n",
       "      <td>Concedendo</td>\n",
       "      <td>Conhecido o recurso e provido</td>\n",
       "      <td>11806,9607</td>\n",
       "      <td>1</td>\n",
       "      <td>[ \\n \\nEXCELENTÍSSIMO SENHOR DOUTOR DESEMBARGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>184045496</td>\n",
       "      <td>202300476053</td>\n",
       "      <td>MARIA ISABEL GALLOTTI</td>\n",
       "      <td>Concedendo</td>\n",
       "      <td>Conhecido o recurso e provido em parte</td>\n",
       "      <td>9607</td>\n",
       "      <td>1</td>\n",
       "      <td>[ \\n \\nPágina 1 de 32 \\n \\nEXMO. DESEMBARGADOR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      seqDocumento  numeroRegistro                      ministro  \\\n",
       "0        178153183    202300036881        JOÃO OTÁVIO DE NORONHA   \n",
       "1        181376805    202202985103                NANCY ANDRIGHI   \n",
       "2        196160898    202301575526  MARIA THEREZA DE ASSIS MOURA   \n",
       "3        220390496    202302743171  MARIA THEREZA DE ASSIS MOURA   \n",
       "4        216103802    202302956038  MARIA THEREZA DE ASSIS MOURA   \n",
       "...            ...             ...                           ...   \n",
       "1495     192080215    202300721459        JOÃO OTÁVIO DE NORONHA   \n",
       "1496     204842588    202203536482        JOÃO OTÁVIO DE NORONHA   \n",
       "1497     179332552    202203993058                   MARCO BUZZI   \n",
       "1498     190594784    202301534845                NANCY ANDRIGHI   \n",
       "1499     184045496    202300476053         MARIA ISABEL GALLOTTI   \n",
       "\n",
       "                teor                               descricaoMonocratica  \\\n",
       "0            Negando                  Conhecido o recurso e não-provido   \n",
       "1            Negando  Agravo conhecido para não conhecer do Recurso ...   \n",
       "2     Não Conhecendo                            Não conhecido o recurso   \n",
       "3     Não Conhecendo                            Não conhecido o recurso   \n",
       "4     Não Conhecendo                            Não conhecido o recurso   \n",
       "...              ...                                                ...   \n",
       "1495      Concedendo                      Conhecido o recurso e provido   \n",
       "1496      Concedendo             Conhecido o recurso e provido em parte   \n",
       "1497      Concedendo                      Conhecido o recurso e provido   \n",
       "1498      Concedendo                      Conhecido o recurso e provido   \n",
       "1499      Concedendo             Conhecido o recurso e provido em parte   \n",
       "\n",
       "                  assuntos  y  \\\n",
       "0                     9607  0   \n",
       "1                     9607  0   \n",
       "2                     9607  0   \n",
       "3                     9607  0   \n",
       "4                     9607  0   \n",
       "...                    ... ..   \n",
       "1495  12401,7779,7780,9607  1   \n",
       "1496                  9607  1   \n",
       "1497                  9607  1   \n",
       "1498            11806,9607  1   \n",
       "1499                  9607  1   \n",
       "\n",
       "                                                  texto  \n",
       "0     [Rua Pedro Ferreira, nº 155 - 7º Andar - Sala ...  \n",
       "1     [ \\nPJ 571059\\nEXCELENTÍSSIMO SENHOR DOUTOR DE...  \n",
       "2     [ \\nBANDEIRA & BARROS\\nAdvocacia e Consultoria...  \n",
       "3     [Num. 161104655 - Pág. 1\\nAssinado eletronicam...  \n",
       "4     [ \\n \\n \\nEXCELENTÍSSIMO SENHOR DESEMBARGADOR ...  \n",
       "...                                                 ...  \n",
       "1495  [ \\nPágina 1 de 17 \\n \\n \\n \\nEXMO. SR. DR. DE...  \n",
       "1496  [ \\n \\nAv. T 05, Qd. 04, Lote 17, Sala Térrea,...  \n",
       "1497  [MARINGÁ/PR \\nEndereço: Rua João Paulino Vieir...  \n",
       "1498  [ \\n \\nEXCELENTÍSSIMO SENHOR DOUTOR DESEMBARGA...  \n",
       "1499  [ \\n \\nPágina 1 de 32 \\n \\nEXMO. DESEMBARGADOR...  \n",
       "\n",
       "[1500 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_feather('./dataframes/texto_raw.feather')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b617c3-f369-4e71-b03e-0a3db95936bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nJUDICIÁRIA. \\nPESSOA \\nJURÍDICA. \\nPOSSIBILIDADE. \\nSÚMULA \\n481/STJ. \\nDEFERIMENTO. 1. De acordo com a norma \\nprevista no art. 1.022 do CPC/2015, são \\ncabíveis embargos de declaração nas hipóteses \\nde obscuridade, contradição ou omissão da \\ndecisão recorrida. 2. No caso, verificada a \\nomissão no acórdão embargado, quanto ao \\npedido de assistência judiciária gratuita, cabível \\no acolhimento dos embargos para apreciação \\ndo pleito. 3. Conforme a Súmula 481/STJ, \"Faz \\njus ao benefício da justiça gratuita a pessoa \\njurídica com ou sem fins lucrativos que \\ndemonstrar sua impossibilidade de arcar \\ncom os encargos processuais. 4. Hipótese \\nem que ficou evidenciada a situação de \\nhipossuficiência \\nfinanceira \\nda \\npessoa \\njurídica embargante, cabendo, por isso, o \\ndeferimento do benefício da assistência \\njudiciária gratuita em seu favor, conforme \\nprevisto no art. 98 do CPC/2015, sem prejuízo \\nda ressalva contida no § 3º desse mesmo \\ndispositivo. 5. Vigora no Superior Tribunal de \\nJustiça o entendimento de que a concessão \\ndo benefício da gratuidade de justiça opera \\nefeitos ex nunc. 6. Embargos de declaração \\nacolhidos, com o deferimento do benefício da \\nassistência judiciária gratuita ao Hospital Nossa \\nSenhora da Conceição S/A. (EDcl no AgInt no \\nREsp 1456947/RS, Rel. Ministro SÉRGIO \\nPara conferir o original, acesse o site https://esaj.tjsp.jus.br/pastadigital/sgcr/abrirConferenciaDocumento.do, informe o processo 2123101-11.2021.8.26.0000 e código 17CCFC55.\\nEste documento é cópia do original, assinado digitalmente por FELIPE PORFIRIO GRANITO e Tribunal de Justica do Estado de Sao Paulo, protocolado em 09/12/2021 às 11:50 , sob o número WPRO21014950201.\\nfls. 6\\n(e-STJ Fl.134)\\nDocumento recebido eletronicamente da origem\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exemplo de texto extraído de uma página\n",
    "df.iloc[5]['texto'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42b8e5c-ab4e-44d4-b686-cb2d3f7c40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0e3ec-6aee-4b9f-a249-9d98ff4bb8ef",
   "metadata": {},
   "source": [
    "### 3.2 Pré-processamento do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a47712-52ad-449b-856d-98848cf88a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para aplicar Regex em cada página da lista\n",
    "def substituir_pagina(lista_paginas, regex_padrão, substituição):\n",
    "    \"\"\"\n",
    "    Aplica uma substituição usando regex em cada página de uma lista.\n",
    "    \n",
    "    Parâmetros:\n",
    "    lista_paginas (list): Lista contendo o texto de cada página.\n",
    "    regex_padrão (str): A expressão regular a ser usada para encontrar o texto a ser substituído.\n",
    "    substituição (str): O texto que substituirá as ocorrências encontradas pelo regex.\n",
    "    \n",
    "    Retorna:\n",
    "    list: Lista com as páginas atualizadas após as substituições.\n",
    "    \"\"\"\n",
    "    return [pd.Series(pagina).str.replace(regex_padrão, substituição, regex=True).values[0]\n",
    "            for pagina in lista_paginas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af40da3e-a5d3-48c4-b0ed-c307fea420cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para aplicar a função anterior em todo o dataframe\n",
    "def aplicar_regex(regex_padrão, substituição, dataframe=df):\n",
    "    \"\"\"\n",
    "    Aplica uma substituição usando regex a todas as páginas na coluna 'texto' de um DataFrame.\n",
    "    \n",
    "    Parâmetros:\n",
    "    dataframe (pd.DataFrame): O DataFrame contendo a coluna 'texto' com listas de páginas.\n",
    "    regex_padrão (str): A expressão regular a ser usada para encontrar o texto a ser substituído.\n",
    "    substituição (str): O texto que substituirá as ocorrências encontradas pelo regex.\n",
    "    \n",
    "    Retorna:\n",
    "    pd.DataFrame: O DataFrame atualizado com as substituições aplicadas.\n",
    "    \"\"\"\n",
    "    # Aplica a função de substituição à coluna 'texto'\n",
    "    dataframe['texto'] = dataframe['texto'].apply(substituir_pagina, args=(regex_padrão, substituição))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab4bbe4-a6ba-4ca6-b9d9-9f04997fca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista de substituições\n",
    "#Essa lista contém as palavras ou expressões que serão removidas \n",
    "lista_remover1 =[\n",
    "r'-\\n', #Remove as quebras de linha com hífen, ou seja, palavras que quebraram a linha e queremos que sejam juntadas novamente\n",
    "r'Documento recebido eletronicamente da origem', #Expressão constante em todas as petições baixadas\n",
    "r'\\(e-STJ Fl\\.\\d+\\)' #Numeração presente em todas as páginas dos arquivos\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da2ae0a-d454-4830-add6-37f18d0d7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove a lista de expressões acima das páginas do dataframe\n",
    "for i in lista_remover1:\n",
    "    df = aplicar_regex(i, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ab2b7fe-941a-4299-8dd7-97ee91514042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove quebras de linha\n",
    "df = aplicar_regex(r'\\n', ' ')\n",
    "#Remove mais de um espaço em branco\n",
    "df = aplicar_regex(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c267e75-d1fc-4e61-a721-3d0d7500b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando para remover diacríticos do dataframe\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [''.join(c for c in unicodedata.normalize('NFD', pagina) if unicodedata.category(c) != 'Mn') for pagina in paginas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08be2fa7-4db1-441d-819b-9bf41aae358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comando para covnerter todas as palavras em minúsculas\n",
    "df['texto'] = df['texto'].apply(lambda paginas: [pagina.lower() for pagina in paginas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baff9102-29af-4b97-a3b2-972093318b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comando para remover hyperlinks\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [re.sub(r'http[s]?://\\S+|www\\.\\S+', '', pagina) for pagina in paginas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5a428f5-f389-4ee6-a39b-01265ca80baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando para remover números no formato CNJ 0000000-00.0000.0.00.0000\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [re.sub(r'\\b\\d{7}-\\d{2}\\.\\d{4}\\.\\d{1}\\.\\d{2}\\.\\d{4}\\b', '', pagina) for pagina in paginas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e27cb27-82fc-4525-93e7-81f2a910189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove mais de um espaço em branco\n",
    "df = aplicar_regex(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b27b9a50-63d5-4327-b0ce-9c1e79a6d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando para remover a assinatura das petições encaminhadas do TJSP e outros tribunais que usam o SAJ.\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [re.sub(r'para conferir o original, acesse o site informe o processo e codigo \\w{8}\\.', '', pagina, flags=re.IGNORECASE) for pagina in paginas])\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [re.sub(r'este documento e copia do original, assinado digitalmente por .*?, protocolado em \\d{2}/\\d{2}/\\d{4} as \\d{2}:\\d{2} , sob o numero [A-Za-z]{4}\\d{11}\\.', '', pagina, flags=re.IGNORECASE) for pagina in paginas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1520048-31ed-4c9e-8647-a33f7836d8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove a expressão 'fls. ... ' com o número das folhas do processo.\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [re.sub(r'fls\\. \\d+', '', pagina) for pagina in paginas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daf39620-e6ef-4347-a3f6-96b3ca6147db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove a assinatura padrão do PJe\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [re.sub(r'assinado eletronicamente por: .*? - \\d{2}/\\d{2}/\\d{4} \\d{2}:\\d{2}:\\d{2}', '', pagina, flags=re.IGNORECASE) for pagina in paginas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "beae20ae-4add-41c1-927c-a72205ac4ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove a assinatura do projudi/pr\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [re.sub(r'documento assinado digitalmente, conforme mp nº 2.200-2/2001, lei nº 11.419/2006, resolucao do projudi, do tjpr/oe', '', pagina, flags=re.IGNORECASE) for pagina in paginas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a366cc9-6a11-40a3-ad5e-e7e57d030f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove a pontuação dos textos\n",
    "pontuacao = r'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~¹²³ªº°®©øØ'\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [re.sub(f'[{re.escape(pontuacao)}]', '', pagina) for pagina in paginas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f560c10-ea7f-4230-a3f7-464d44328920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove o texto 'página x de x'\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [re.sub(r'pagina \\d{1,3} de \\d{1,3}', '', pagina, flags=re.IGNORECASE) for pagina in paginas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ece9c875-91b2-403e-8be8-27160d2cc381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comando para remover palavras de uma letra só e stopwords\n",
    "df['texto'] = df['texto'].apply(lambda paginas: \n",
    "    [' '.join([palavra for palavra in re.findall(r'\\b\\w+\\b', pagina) if len(palavra) > 1 and palavra.lower() not in stop_words]) for pagina in paginas])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63924ea-2ec5-43d5-b2cc-c6528412e8de",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3792549-1e3f-4b37-83d0-36fe7f5e51d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria a coluna palavra comuns\n",
    "df['palavrasComuns'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a27a36f7-c56d-48c8-b769-9e70b9589510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para encontrar palavras comuns em todas as páginas de um recurso\n",
    "def encontrar_palavras_comuns(lista_textos):\n",
    "    # Verifica se a lista está vazia ou se não contém textos\n",
    "    if lista_textos is None or len(lista_textos) == 0:\n",
    "        return set()  # Retorna um conjunto vazio se não houver páginas\n",
    "    \n",
    "    # Inicializa o conjunto com as palavras da primeira página, considerando palavras não vazias\n",
    "    palavras_comuns = set(lista_textos[0].split())\n",
    "    \n",
    "    # Itera pelas páginas restantes e realiza a interseção\n",
    "    for texto in lista_textos[1:]:\n",
    "        palavras_comuns.intersection_update(texto.split())\n",
    "    \n",
    "    # Retorna as palavras comuns, ou None se o conjunto estiver vazio\n",
    "    return palavras_comuns if palavras_comuns else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6897fbeb-4df4-4e7b-82d2-039b611f82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que o DataFrame se chame df e a coluna com as listas de textos seja 'texto_por_pagina'\n",
    "df['palavrasComuns'] = df['texto'].apply(encontrar_palavras_comuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1c077097-de82-4759-9214-b27959e6e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para remover palavras constantes do campo 'palavrasComuns'\n",
    "def remover_palavras_comuns(row):\n",
    "    palavras_comuns = row['palavrasComuns']\n",
    "    \n",
    "    # Verifica se palavrasComuns não é None\n",
    "    if palavras_comuns is None:\n",
    "        return row['texto']  # Retorna o texto original se palavrasComuns for None\n",
    "\n",
    "    texto_filtrado = []\n",
    "    \n",
    "    for pagina in row['texto']:\n",
    "        if pagina is not None:  # Verifica se a página não é None\n",
    "            # Remove as palavras comuns usando regex\n",
    "            pagina_filtrada = ' '.join([palavra for palavra in re.findall(r'\\b\\w+\\b', pagina) if palavra.lower() not in palavras_comuns])\n",
    "            texto_filtrado.append(pagina_filtrada)\n",
    "        else:\n",
    "            texto_filtrado.append(None)  # Adiciona None se a página for None\n",
    "    \n",
    "    return texto_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "80d041d4-b84d-4aaa-b572-e240f533e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a função no DataFrame\n",
    "df['texto'] = df.apply(remover_palavras_comuns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcdc318-5109-4392-bc2c-dc23fee088e4",
   "metadata": {},
   "source": [
    "----\n",
    "Texto está processado, hora de colocar em uma única coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d7b3c090-b626-4c04-bbfb-6758b2f11e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['textoProcessado'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "38e26dec-9c6e-40f4-82a6-f89a7601d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para juntar o texto de todas as páginas\n",
    "def juntar_texto(paginas):\n",
    "    if paginas is None:  # Verifica se as páginas são None\n",
    "        return None\n",
    "    return ' '.join(paginas)  # Junta todas as páginas em uma única string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "049aaff9-bc66-437a-a509-8c469c844875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a nova coluna 'textoProcessado'\n",
    "df['textoProcessado'] = df['texto'].apply(juntar_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e8725-fed6-4f8e-9138-2c136a079943",
   "metadata": {},
   "source": [
    "Hora de dividir entre treino e teste e testar os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43597c12-4e87-460a-9bd0-2ddae7d4d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df['textoProcessado']\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ba09ae4e-f552-400e-8837-75c16c8da91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ab9a2c76-7af3-49cd-a363-ef9d566e074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a1e60ff4-eea4-4bf3-99d9-0d6c059bde0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "61743d66-e2a9-4069-aa26-7e9c5756a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fed87122-2229-4b71-b184-c73b71ba9ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       146\n",
      "           1       0.75      0.72      0.74       154\n",
      "\n",
      "    accuracy                           0.73       300\n",
      "   macro avg       0.73      0.73      0.73       300\n",
      "weighted avg       0.73      0.73      0.73       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60055e5-349d-4f92-a79a-55db60810be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "522a049f-1acc-49e3-98a6-e913d6931f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78       146\n",
      "           1       0.79      0.79      0.79       154\n",
      "\n",
      "    accuracy                           0.79       300\n",
      "   macro avg       0.79      0.79      0.79       300\n",
      "weighted avg       0.79      0.79      0.79       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e21e3da4-8290-4fae-a6b4-f6dbe5effcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74       146\n",
      "           1       0.77      0.69      0.73       154\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.74      0.74      0.74       300\n",
      "weighted avg       0.74      0.74      0.74       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5580cdac-52be-42d6-a4f2-4597739ed32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venvs/TCC/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:22:28] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       146\n",
      "           1       0.76      0.78      0.77       154\n",
      "\n",
      "    accuracy                           0.76       300\n",
      "   macro avg       0.76      0.76      0.76       300\n",
      "weighted avg       0.76      0.76      0.76       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9acf3720-bb82-4459-a72b-4d064b95d6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.79      0.72       146\n",
      "           1       0.76      0.61      0.68       154\n",
      "\n",
      "    accuracy                           0.70       300\n",
      "   macro avg       0.71      0.70      0.70       300\n",
      "weighted avg       0.71      0.70      0.70       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', BernoulliNB())\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2dedfe39-d6fb-4edf-ada8-f69d0ff0a437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras mais significativas para a classe 0:\n",
      "             word  log_prob  importance\n",
      "59242         nao -7.007749    4.327962\n",
      "68702     recurso -7.344974    3.990737\n",
      "28881         art -7.698907    3.636803\n",
      "76641    tribunal -7.800974    3.534736\n",
      "44438    especial -7.910946    3.424764\n",
      "...           ...       ...         ...\n",
      "65753  processual -9.139172    2.196538\n",
      "46671        fato -9.144658    2.191053\n",
      "78410    violacao -9.150354    2.185356\n",
      "30801   beneficio -9.152061    2.183649\n",
      "64026        pois -9.153488    2.182223\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "Palavras mais significativas para a classe 1:\n",
      "             word  log_prob  importance\n",
      "59242         nao -7.015265    4.321478\n",
      "68702     recurso -7.452426    3.884317\n",
      "28881         art -7.562240    3.774503\n",
      "54842       juros -7.590504    3.746239\n",
      "75167        taxa -7.694236    3.642508\n",
      "...           ...       ...         ...\n",
      "66418    proveito -9.052249    2.284495\n",
      "65127  prescricao -9.063971    2.272773\n",
      "75125     tarifas -9.067854    2.268889\n",
      "72665     sentido -9.072407    2.264337\n",
      "61632      origem -9.075042    2.261701\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Acessar o TfidfVectorizer do pipeline\n",
    "tfidf_vectorizer = pipeline.named_steps['tfidf']\n",
    "# Acessar o classificador\n",
    "classifier = pipeline.named_steps['clf']\n",
    "\n",
    "# Obter os nomes das características (palavras)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Obter as probabilidades logarítmicas\n",
    "log_probs = classifier.feature_log_prob_\n",
    "\n",
    "# Para cada classe, obter as palavras mais significativas\n",
    "for class_index in range(log_probs.shape[0]):\n",
    "    # Criar um DataFrame com as palavras e suas probabilidades logarítmicas\n",
    "    word_probs = pd.DataFrame({\n",
    "        'word': feature_names,\n",
    "        'log_prob': log_probs[class_index]\n",
    "    })\n",
    "\n",
    "    # Calcular a importância das palavras\n",
    "    word_probs['importance'] = word_probs['log_prob'] - log_probs.mean(axis=1)[class_index]\n",
    "\n",
    "    # Ordenar as palavras pela importância\n",
    "    significant_words = word_probs.sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # Exibir as 10 palavras mais significativas para a classe\n",
    "    print(f'Palavras mais significativas para a classe {class_index}:')\n",
    "    print(significant_words.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "475b507a-3f0f-426a-a668-5313048736d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras mais significativas para a classe 0:\n",
      "                    word  log_prob  importance\n",
      "59242                nao -7.007749    4.327962\n",
      "68702            recurso -7.344974    3.990737\n",
      "28881                art -7.698907    3.636803\n",
      "76641           tribunal -7.800974    3.534736\n",
      "44438           especial -7.910946    3.424764\n",
      "54894            justica -7.931669    3.404041\n",
      "25155            acordao -7.952622    3.383088\n",
      "65714           processo -8.115502    3.220208\n",
      "68552         recorrente -8.115974    3.219736\n",
      "38184            decisao -8.122858    3.212852\n",
      "65158           presente -8.166324    3.169386\n",
      "33332              civil -8.212248    3.123462\n",
      "55539                lei -8.238977    3.096733\n",
      "29013             artigo -8.248563    3.087148\n",
      "54842              juros -8.269853    3.065857\n",
      "30012              autos -8.297427    3.038283\n",
      "46824            federal -8.311150    3.024560\n",
      "62561              parte -8.321246    3.014464\n",
      "40947            direito -8.323913    3.011798\n",
      "36282           contrato -8.333001    3.002709\n",
      "33715             codigo -8.350085    2.985626\n",
      "26301             agravo -8.353519    2.982192\n",
      "37082            credito -8.372164    2.963547\n",
      "24794               acao -8.383631    2.952079\n",
      "32183             cartao -8.391157    2.944554\n",
      "32249               caso -8.412967    2.922743\n",
      "72631           sentenca -8.456454    2.879256\n",
      "30440              banco -8.462858    2.872853\n",
      "68608          recorrido -8.470639    2.865072\n",
      "74594           superior -8.500493    2.835217\n",
      "36892                cpc -8.503357    2.832353\n",
      "35783         consumidor -8.517777    2.817934\n",
      "77572              valor -8.554921    2.780790\n",
      "45497           execucao -8.559897    2.775813\n",
      "42944           embargos -8.596425    2.739286\n",
      "75554             termos -8.599356    2.736355\n",
      "29219              assim -8.601298    2.734412\n",
      "50410                iii -8.657997    2.677714\n",
      "27926           apelacao -8.673214    2.662497\n",
      "47832              forma -8.691696    2.644014\n",
      "65127         prescricao -8.743021    2.592689\n",
      "37774               dano -8.744553    2.591157\n",
      "35125           conforme -8.747288    2.588422\n",
      "72113                sao -8.751933    2.583777\n",
      "73346              sobre -8.752846    2.582865\n",
      "75167               taxa -8.760130    2.575581\n",
      "30753                bem -8.760686    2.575024\n",
      "66379              prova -8.770661    2.565049\n",
      "49866         honorarios -8.774454    2.561257\n",
      "73974                stj -8.826207    2.509503\n",
      "62195          pagamento -8.828886    2.506825\n",
      "54174                 ja -8.829681    2.506029\n",
      "38520             defesa -8.838087    2.497623\n",
      "52831        instrumento -8.843089    2.492622\n",
      "51455             inciso -8.846980    2.488730\n",
      "54611         julgamento -8.855025    2.480685\n",
      "72581              sendo -8.878277    2.457433\n",
      "37850               data -8.878291    2.457420\n",
      "58526              moral -8.880192    2.455518\n",
      "68575        recorrentes -8.883659    2.452051\n",
      "26463              ainda -8.885305    2.450405\n",
      "33323              civel -8.886195    2.449515\n",
      "38229         declaracao -8.888586    2.447124\n",
      "68594          recorrida -8.918261    2.417450\n",
      "64641              prazo -8.926014    2.409697\n",
      "63078            penhora -8.944368    2.391342\n",
      "74513             sumula -8.946951    2.388759\n",
      "35449         consignado -8.948912    2.386799\n",
      "43725       entendimento -8.950319    2.385391\n",
      "66505         provimento -8.950969    2.384741\n",
      "50712             imovel -8.964963    2.370747\n",
      "57415            materia -8.972814    2.362897\n",
      "49424                 ha -8.973821    2.361889\n",
      "61518                ora -8.981594    2.354116\n",
      "43216         emprestimo -9.033864    2.301846\n",
      "54582            julgado -9.034815    2.300896\n",
      "76846              turma -9.037742    2.297968\n",
      "40424               deve -9.047505    2.288205\n",
      "62939             pedido -9.055460    2.280251\n",
      "68018             razoes -9.057664    2.278047\n",
      "31756             camara -9.061965    2.273746\n",
      "33654           cobranca -9.062175    2.273536\n",
      "77592            valores -9.063675    2.272036\n",
      "37777              danos -9.063771    2.271940\n",
      "54556              juizo -9.066495    2.269216\n",
      "50364                 ii -9.067341    2.268370\n",
      "29914             autora -9.089123    2.246588\n",
      "70344               resp -9.107444    2.228267\n",
      "3780                 105 -9.109228    2.226483\n",
      "35624       constituicao -9.119312    2.216398\n",
      "65076  prequestionamento -9.121005    2.214705\n",
      "54757           juridica -9.121916    2.213795\n",
      "49135           gratuita -9.127925    2.207786\n",
      "66910           qualquer -9.129711    2.205999\n",
      "36797              corte -9.135553    2.200157\n",
      "65753         processual -9.139172    2.196538\n",
      "46671               fato -9.144658    2.191053\n",
      "78410           violacao -9.150354    2.185356\n",
      "30801          beneficio -9.152061    2.183649\n",
      "64026               pois -9.153488    2.182223\n",
      "Palavras mais significativas para a classe 1:\n",
      "                    word  log_prob  importance\n",
      "59242                nao -7.015265    4.321478\n",
      "68702            recurso -7.452426    3.884317\n",
      "28881                art -7.562240    3.774503\n",
      "54842              juros -7.590504    3.746239\n",
      "75167               taxa -7.694236    3.642508\n",
      "76641           tribunal -7.729351    3.607393\n",
      "25155            acordao -7.771747    3.564997\n",
      "44438           especial -7.926339    3.410405\n",
      "54894            justica -8.084365    3.252378\n",
      "57575              media -8.108771    3.227973\n",
      "32249               caso -8.230827    3.105917\n",
      "38184            decisao -8.253444    3.083299\n",
      "33332              civil -8.270770    3.065974\n",
      "65714           processo -8.283413    3.053330\n",
      "68552         recorrente -8.297193    3.039551\n",
      "29013             artigo -8.301291    3.035453\n",
      "24744        abusividade -8.305005    3.031739\n",
      "26301             agravo -8.306961    3.029783\n",
      "65158           presente -8.318546    3.018198\n",
      "69669     remuneratorios -8.329282    3.007462\n",
      "36892                cpc -8.352575    2.984169\n",
      "36282           contrato -8.356194    2.980550\n",
      "57794            mercado -8.367366    2.969377\n",
      "55539                lei -8.376245    2.960498\n",
      "68608          recorrido -8.384743    2.952001\n",
      "24794               acao -8.384803    2.951940\n",
      "74594           superior -8.389684    2.947060\n",
      "42944           embargos -8.392004    2.944740\n",
      "46824            federal -8.395109    2.941634\n",
      "77572              valor -8.417098    2.919645\n",
      "33715             codigo -8.426676    2.910067\n",
      "72631           sentenca -8.467567    2.869177\n",
      "62561              parte -8.476230    2.860514\n",
      "30012              autos -8.495526    2.841218\n",
      "73974                stj -8.517599    2.819144\n",
      "49866         honorarios -8.536306    2.800438\n",
      "73346              sobre -8.537314    2.799429\n",
      "50785  impenhorabilidade -8.548832    2.787912\n",
      "70344               resp -8.569137    2.767607\n",
      "40947            direito -8.601290    2.735453\n",
      "30440              banco -8.624687    2.712056\n",
      "43725       entendimento -8.635583    2.701160\n",
      "29219              assim -8.648835    2.687909\n",
      "75171              taxas -8.651726    2.685018\n",
      "38229         declaracao -8.671474    2.665270\n",
      "45497           execucao -8.677024    2.659720\n",
      "54611         julgamento -8.683127    2.653617\n",
      "75554             termos -8.709738    2.627005\n",
      "50410                iii -8.712458    2.624285\n",
      "47832              forma -8.729287    2.607457\n",
      "37082            credito -8.739719    2.597024\n",
      "58506               mora -8.762713    2.574031\n",
      "54582            julgado -8.783659    2.553085\n",
      "56048         liquidacao -8.816526    2.520217\n",
      "27926           apelacao -8.848743    2.488001\n",
      "32343              causa -8.858677    2.478066\n",
      "22901                833 -8.863090    2.473653\n",
      "30753                bem -8.864038    2.472706\n",
      "36797              corte -8.868642    2.468102\n",
      "35783         consumidor -8.891849    2.444894\n",
      "74513             sumula -8.893166    2.443578\n",
      "52831        instrumento -8.894563    2.442180\n",
      "40428            devedor -8.903220    2.433523\n",
      "51455             inciso -8.909508    2.427235\n",
      "35125           conforme -8.912371    2.424372\n",
      "72581              sendo -8.918618    2.418126\n",
      "64461           poupanca -8.926266    2.410477\n",
      "77592            valores -8.940445    2.396298\n",
      "50364                 ii -8.948121    2.388623\n",
      "76846              turma -8.950126    2.386618\n",
      "23020                 85 -8.950448    2.386296\n",
      "35888             contas -8.951678    2.385066\n",
      "30309              bacen -8.952322    2.384422\n",
      "72113                sao -8.953080    2.383664\n",
      "35824              conta -8.953197    2.383547\n",
      "40424               deve -8.954141    2.382603\n",
      "49424                 ha -8.956254    2.380490\n",
      "33323              civel -8.957639    2.379104\n",
      "31941      capitalizacao -8.959568    2.377176\n",
      "54825     jurisprudencia -8.961637    2.375107\n",
      "66505         provimento -8.969303    2.367440\n",
      "54174                 ja -8.973884    2.362860\n",
      "69401                rel -8.982348    2.354396\n",
      "36295          contratos -8.991673    2.345071\n",
      "37850               data -8.994088    2.342656\n",
      "3494                1022 -8.995882    2.340861\n",
      "63078            penhora -8.996711    2.340033\n",
      "61518                ora -9.000124    2.336620\n",
      "57415            materia -9.004001    2.332743\n",
      "33654           cobranca -9.006290    2.330454\n",
      "3780                 105 -9.011404    2.325340\n",
      "78410           violacao -9.012777    2.323967\n",
      "26463              ainda -9.024206    2.312538\n",
      "41546                dje -9.031303    2.305441\n",
      "37439        cumprimento -9.039552    2.297192\n",
      "66418           proveito -9.052249    2.284495\n",
      "65127         prescricao -9.063971    2.272773\n",
      "75125            tarifas -9.067854    2.268889\n",
      "72665            sentido -9.072407    2.264337\n",
      "61632             origem -9.075042    2.261701\n"
     ]
    }
   ],
   "source": [
    "# Obter os nomes das características (palavras)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Obter as probabilidades logarítmicas\n",
    "log_probs = classifier.feature_log_prob_\n",
    "\n",
    "# Configurar o Pandas para mostrar todas as linhas\n",
    "pd.set_option('display.max_rows', None)  # None para mostrar todas as linhas\n",
    "pd.set_option('display.max_columns', None)  # None para mostrar todas as colunas\n",
    "\n",
    "# Para cada classe, obter as palavras mais significativas\n",
    "for class_index in range(log_probs.shape[0]):\n",
    "    # Criar um DataFrame com as palavras e suas probabilidades logarítmicas\n",
    "    word_probs = pd.DataFrame({\n",
    "        'word': feature_names,\n",
    "        'log_prob': log_probs[class_index]\n",
    "    })\n",
    "\n",
    "    # Calcular a importância das palavras\n",
    "    word_probs['importance'] = word_probs['log_prob'] - log_probs.mean(axis=1)[class_index]\n",
    "\n",
    "    # Ordenar as palavras pela importância\n",
    "    significant_words = word_probs.sort_values(by='importance', ascending=False)\n",
    "\n",
    "    # Exibir todas as palavras significativas para a classe\n",
    "    print(f'Palavras mais significativas para a classe {class_index}:')\n",
    "    print(significant_words.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd936a8-ada5-4a5f-88ff-d08b14df5f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1446f-56e3-4613-8e77-5e8fb9e32987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167c3b5-7d70-40b4-a38b-77b0b519c024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
